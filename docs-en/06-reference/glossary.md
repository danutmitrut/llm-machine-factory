# Glossary of Terms

Key terms used in this package.

---

## A

### AIM (Intelligent Metaprompt Architect)
The central machine in this package. Generates other LLM machines through guided dialogue with the user. Includes 3 synchronization points for maximum control.

### Anti-hallucination
Techniques and instructions designed to reduce the generation of false information by LLMs. Includes proactive filters (during generation) and post-facto verification.

### Anchoring in reality
The principle that output must be tied to concrete data and examples, not just abstract reasoning. Achieved through web search and evidence requests.

---

## B

### Strategic bifurcation
A moment in the reasoning process where there are two or more valid directions to follow. The user chooses the direction at the synchronization point.

### Bootstrapping
A process through which a system improves itself. In this context: the machines were used to generate their own improvements.

---

## C

### Chain of Thought (CoT)
A prompting technique where the LLM is instructed to show its reasoning steps. The theoretical foundation for Metacognitive Machines.

### Cognitive Continuity (Principle)
The fundamental rule that each reasoning step builds EXCLUSIVELY on previous steps. Prevents pre-calculation of the answer and retroactive justification.

### Co-creation
An interaction model where the user and AI build the solution together, through dialogue, not complete delegation.

---

## D

### Fundamental decomposition
A reasoning type: fragmenting a complex problem into simpler components, analyzable individually.

---

## E

### Counterintuitive exploration
A reasoning type: examining hypotheses that contradict initial logic or common intuition. "What if the opposite is true?"

---

## H

### Hallucination
The generation of false, invented, or unfounded information by an LLM, presented as facts. Includes: invented statistics, non-existent concepts, unjustified conclusions.

---

## I

### Iteration
A complete cycle of internal question → answer → conclusion in the reasoning process. The machines use 5-15 iterations per problem.

---

## L

### LLM (Large Language Model)
A large language model (e.g., GPT-4, Claude). The base on which Metacognitive Machines run.

---

## M

### LLM Machine / Metacognitive Machine
Informal term for a complex metaprompt that transforms an LLM into a structured reasoning system with specific capabilities.

### Meta-cognition
Literally: "thinking about thinking." The ability of a system to analyze and evaluate its own reasoning process.

### Metaprompt
A higher-level prompt that defines how an LLM should function for a category of tasks, not just for a specific task.

---

## P

### Synchronization point
A predefined moment in the workflow where the process stops and the AI asks for input from the user. Transforms monologue into dialogue.

### Pre-calculation
Anti-pattern: when the LLM "knows" the answer beforehand and fabricates a retroactive justification. Prevented by the Cognitive Continuity Principle.

---

## R

### Cause-effect reasoning
A reasoning type: investigating causality chains to identify root causes, not just symptoms.

### Visible reasoning
The principle that the user sees the thinking process (iterations), not just the final result. Creates transparency and trust.

### Reflection and adjustment
A reasoning type: periodic stopping to evaluate progress and adjust direction if necessary.

---

## S

### Hallucination risk score
A metric (0-5) indicating the probability that information is hallucinated. 0 = verified, 5 = clearly invented.

### Creative synthesis
A reasoning type: combining disparate elements into a new and innovative solution.

### Simulation vs. thinking
Critical distinction: LLMs can "simulate" that they think (retroactive fabrication) or can "think" authentically (progressive construction). The machines force the second variant.

---

## V

### Internal validation
Checking the logical consistency of a claim without external sources. "Does it make logical sense?"

### External validation
Verifying a claim through web search or evidence requests. "Is there evidence?"

### Veracity
The degree to which a claim corresponds to reality. Measured by the Veracity Auditor.

---

## Next Step

→ [Additional Resources](resources.md)
